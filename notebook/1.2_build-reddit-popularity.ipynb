{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "sc = SparkContext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_label_state = pd.read_csv(\"../data/processed/author-label-state.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download these files from https://files.pushshift.io/reddit/\n",
    "comments_path = '/data/big/reddit/comments/2016/RC_2016-*.bz2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = author_label_state.author.values\n",
    "authors_set = set(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there is one file per month\n",
    "assert len(glob(comments_path)) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_list = {'politics'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_measures(scores_iterable):\n",
    "    \"\"\" Returns a tuple with:\n",
    "        no. of comments, avg, std dev,\n",
    "        no. of pos. comments, avg score of pos. comments, std dev of pos. comments,\n",
    "        no. of neg. comments, avg score of neg. comments, std dev of neg. comments\n",
    "    \"\"\"\n",
    "    scores = list(scores_iterable)\n",
    "    sign2scores = {k: list(v) for k, v in groupby(scores, lambda x: x > 0)}\n",
    "    pos = sign2scores.get(True, [])\n",
    "    neg = sign2scores.get(False, [])\n",
    "    return [\n",
    "        f(v)\n",
    "        for v in [scores, pos, neg]\n",
    "        for f in [len, np.mean, np.std]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_rdd = sc.textFile(comments_path).map(json.loads)\n",
    "rdd_selected_comments = comments_rdd.filter(\n",
    "        lambda x: \n",
    "                'author' in x.keys() and\n",
    "                x['author'] in authors_set and\n",
    "                'subreddit' in x.keys() and\n",
    "                x['subreddit'] in subreddits_list\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_popularity = (rdd_selected_comments\n",
    "     .map(lambda x: (x['author'], float(x['score'])))\n",
    "     .groupByKey() # Result: author -> [post_score_0, ..., post_score_N]\n",
    "     .map(lambda x: tuple([x[0]] + popularity_measures(x[1])))\n",
    "     # Result: author, *popularity_measures\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/processed/scores-of-authors-in-politics-from-author-label-state.csv.bz2\"\n",
    "author_popularity.map(lambda x: ','.join(str(d) for d in x)).repartition(1).saveAsTextFile(\n",
    "    output_path,\n",
    "    compressionCodecClass='org.apache.hadoop.io.compress.BZip2Codec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_path, names=[\n",
    "                'author', 'num_comm', 'avg_score', 'stddev_score', \n",
    "                          'num_comm_pos', 'avg_score_pos', 'stddev_score_pos', \n",
    "                          'num_comm_neg', 'avg_score_neg', 'stddev_score_neg'\n",
    "            ]\n",
    ")\n",
    "os.remove(output_path)\n",
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
